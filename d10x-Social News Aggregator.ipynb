{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install textblob\nimport requests\nimport pandas as pd\nimport json\nfrom pandas.io.json import json_normalize\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_columns', None)  ","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"api_key=\"9ec526b31a214d80bfeb5aa83451239c\"\ntype_of_news=\"everything\" ## everything || top-headlines\ndate_from=\"2019-07-26\"\nquerying_keyword=\"Iron ore\"\npageSize=\"100\"\nsource=\"Reuters\"\nnews_feed_url = ('https://newsapi.org/v2/'+type_of_news+'?q='+querying_keyword+'&from='+date_from+'&sortBy=popularity&sources='+source+'&pageSize='+pageSize+'&apiKey='+api_key)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(news_feed_url):\n    response = requests.get(news_feed_url)\n    return response.json()\n\na=get_data(news_feed_url)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(a)\nnews_data=json_normalize(a['articles'])\ntype(news_data)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"pandas.core.frame.DataFrame"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_stamp=news_data[\"publishedAt\"].str.split(\"T\",n=1,expand=True)\nnews_data[\"published_date\"]=date_stamp[0]\nnews_data[\"published_time\"]=date_stamp[1].str.split(\"Z\",n=1,expand=True)[0]\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_data.head(1)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"              author  \\\n0  Reuters Editorial   \n\n                                                                                                                                                                                                                                                                                content  \\\n0  BEIJING (Reuters) - China’s monthly crude steel output fell for a second straight month in July, official data showed on Wednesday, as steel mills trimmed output amid heightened environmental measures and record raw material prices. \\r\\nThe world’s top steelmak… [+1672 chars]   \n\n                                                                                                                                                                                                            description  \\\n0  China's monthly crude steel output fell for a second straight month in July, official data showed on Wednesday, as steel mills trimmed output amid heightened environmental measures and record raw material prices.   \n\n            publishedAt source.id source.name  \\\n0  2019-08-14T02:38:59Z  reuters   Reuters      \n\n                                                                       title  \\\n0  China's July steel output eases on environmental curbs, shrinking margins   \n\n                                                                           url  \\\n0  https://www.reuters.com/article/us-china-economy-output-steel-idUSKCN1V4062   \n\n                                                                                         urlToImage  \\\n0  https://s3.reutersmedia.net/resources/r/?m=02&d=20190814&t=2&i=1418702817&w=1200&r=LYNXNPEF7D05J   \n\n  published_date published_time  \n0  2019-08-14     02:38:59       ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>content</th>\n      <th>description</th>\n      <th>publishedAt</th>\n      <th>source.id</th>\n      <th>source.name</th>\n      <th>title</th>\n      <th>url</th>\n      <th>urlToImage</th>\n      <th>published_date</th>\n      <th>published_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Reuters Editorial</td>\n      <td>BEIJING (Reuters) - China’s monthly crude steel output fell for a second straight month in July, official data showed on Wednesday, as steel mills trimmed output amid heightened environmental measures and record raw material prices. \\r\\nThe world’s top steelmak… [+1672 chars]</td>\n      <td>China's monthly crude steel output fell for a second straight month in July, official data showed on Wednesday, as steel mills trimmed output amid heightened environmental measures and record raw material prices.</td>\n      <td>2019-08-14T02:38:59Z</td>\n      <td>reuters</td>\n      <td>Reuters</td>\n      <td>China's July steel output eases on environmental curbs, shrinking margins</td>\n      <td>https://www.reuters.com/article/us-china-economy-output-steel-idUSKCN1V4062</td>\n      <td>https://s3.reutersmedia.net/resources/r/?m=02&amp;d=20190814&amp;t=2&amp;i=1418702817&amp;w=1200&amp;r=LYNXNPEF7D05J</td>\n      <td>2019-08-14</td>\n      <td>02:38:59</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_data.to_csv('data_reuters_iron.csv')","execution_count":7,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'data_reuters_iron.csv')","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"/kaggle/working/data_reuters_iron.csv","text/html":"<a href='data_reuters_iron.csv' target='_blank'>data_reuters_iron.csv</a><br>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nnltk.download('punkt') # one time execution\nimport re\n!pip install rouge\nfrom rouge import Rouge\nrouge = Rouge()\nimport string\nimport networkx as nx\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Function to tokenize sentences properly\ndef clean_tokenize(full_text):\n    full_text = re.sub(r\"\\\\'\", \"'\", full_text)        # few modifications in text\n    full_text = re.sub(r\"U.S.\", \"US\", full_text)\n    #full_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", full_text)\n    full_text = full_text.replace('\\n','')\n  \n  \n    tokenized = nltk.sent_tokenize(full_text)         # nltk tokenizer\n  \n    for sentence in tokenized:                        # identifying correct positions for tokenization\n        x=re.findall(r'\\w+[.?!][A-Z]+', sentence)\n        all_delm = []\n        punctuation = [\".\",\"!\",\"?\"]\n        for punct in punctuation:\n            for occurrence in x:\n                try:\n                    idx1 = occurrence.index(punct)\n                    idx2 = sentence.index(occurrence)\n                    punct_idx = idx1+idx2\n                    all_delm .append(punct_idx)\n                except:\n                    continue\n          \n        all_delm.sort()\n        good_tok = []\n        lower_idx = 0\n        higher_idx = 0\n    \n        for i in range(len(all_delm)):                  # creating list of properly tokenized text\n            if i!=0:\n                lower_idx = all_delm[i-1]+1\n            higher_idx = all_delm[i]+1\n            good_tok.append(sentence[lower_idx:higher_idx])\n        good_tok.append(sentence[higher_idx:])\n    \n        sent_idx = tokenized.index(sentence)            \n        for i in range(len(good_tok)):\n            tokenized.insert(sent_idx+i+1, good_tok[i])\n        tokenized.pop(sent_idx)\n  \n    #print (tokenized)\n    return tokenized","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# function to remove stopwords\ndef remove_stopwords(sen):\n    sen_new = \" \".join([i for i in sen if i not in stop_words])\n    return sen_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"embeddings_index = {}\nf = open('../input/glove840b300dtxt/glove.840B.300d.txt')\nfor line in f:\n    values = line.split(' ')\n    word = values[0] ## The first entry is the word\n    coefs = np.asarray(values[1:], dtype='float32') ## These are the vecotrs representing the embedding for the word\n    embeddings_index[word] = coefs\nf.close()\n\nprint('GloVe data loaded')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# convert sentence to vector\ndef convert_to_vectors(clean_sentences):\n    sentence_vectors = []\n    for i in clean_sentences:\n        if len(i) != 0:\n            v = sum([embeddings_index.get(w, np.zeros((300,))) for w in i.split()])/(len(i.split())+0.001)\n        else:\n            v = np.zeros((300,))\n        sentence_vectors.append(v)\n    return sentence_vectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# calculate similarity of sentences\ndef calculate_similarities(clean_sentences,sentence_vectors):\n    sim_mat = np.zeros([len(clean_sentences), len(clean_sentences)])           # create similarity matrix\n    for i in range(len(clean_sentences)):\n        for j in range(len(clean_sentences)):\n            if i != j:\n                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,300), sentence_vectors[j].reshape(1,300))[0,0]\n    return sim_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# use textrank algorithm to calculate similarity\ndef TextRank(sim_mat):\n    nx_graph = nx.from_numpy_array(sim_mat)\n    scores = nx.pagerank(nx_graph)\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.read_csv(\"../input/bbc-extractive-csv/bbc.csv\")\nprint (data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"articles = list(data['articles'])\nsummaries = list(data['summaries'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def generate_summary(text):\n    sentences = clean_tokenize(text)                                                              # tokenize text\n    sentences = list(filter(lambda a: a != \"\", sentences))                                        # remove empty string if any (Encode methods gives error if empty string is encountered)\n    clean_sentences = pd.Series(sentences)                                                        # make a copy in pandas for processing\n    clean_sentences = clean_sentences.apply(lambda s: s.translate(str.maketrans('', '', string.punctuation)))\n    clean_sentences = [s.lower() for s in clean_sentences]                                        # make alphabets lowercase\n    clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]                      # remove stopwords from the sentences\n    sentence_vectors = convert_to_vectors(clean_sentences)                                        # create vectors for sentences\n    sim_mat = calculate_similarities(clean_sentences,sentence_vectors)                            # calculate similarities between sentences\n    scores = TextRank(sim_mat)                                                                    # applying textrank algorithm\n    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)      # sort sentences on the basis of similarity\n    \n    #-----Generating Summary-----#\n    sn = 5                                                                                      # Specify number of sentences to form the summary\n    summary = {}\n    for i in range(sn):\n        summary[sentences.index(ranked_sentences[i][1])] = ranked_sentences[i][1]\n    \n    final = \"\"\n    for i in sorted (summary) : \n        final+= str(summary[i])+\" \"\n    return final","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"avg_rouge = [0]*9","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in range(500):  #range = len(articles)\n    actual_summary = summaries[i]\n    hypothesis = generate_summary(articles[i])\n    \n    print (\"Actual Summary : \", end = \"\")\n    print (actual_summary)\n    print (\"\\n\")\n    print (\"Predicted Summary : \", end = \"\")\n    print (hypothesis)\n    print (\"\\n\")\n    print (\"Rouge Score : \", end = \"\")\n    score = rouge.get_scores(hypothesis, actual_summary)\n    print (score)\n    \n    dic = score[0]\n    j = 0\n    for k1,v1 in dic.items():\n        for k2,v2 in v1.items():\n            avg_rouge[j%9]+= v2\n            j+=1\n    \n    print (\"\\n\")\n    print (\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"n = len(avg_rouge)\nfor i in range(n):    \n    avg_rouge[i]/=500    # divide by len(articles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"-------Rouge Scores-------\")\nprint (\"-----------with-----------\")\nprint (\"-----GLOVE Embeddings-----\")\n'''\nprint (\"Rouge 1\")\nprint (\"f = \",avg_rouge[0])\nprint (\"p = \",avg_rouge[1])\nprint (\"r = \",avg_rouge[2])\nprint (\"\\n\")\nprint (\"Rouge 2\")\nprint (\"f = \",avg_rouge[3])\nprint (\"p = \",avg_rouge[4])\nprint (\"r = \",avg_rouge[5])\nprint (\"\\n\")\n'''\nprint (\"\\n\")\nprint (\"Rouge L\")\nprint (\"f = \",avg_rouge[6])\nprint (\"p = \",avg_rouge[7])\nprint (\"r = \",avg_rouge[8])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}